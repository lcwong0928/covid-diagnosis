{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "testing_different_architectures_datalab_final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "codeCollapsed": false,
        "hiddenCell": true,
        "id": "W54HH0U8JQuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyPi Tensorflow and utilities installation for Datalab\n",
        "!pip install --upgrade pip\n",
        "!pip uninstall -y tensorflow PyHamcrest google-api-core google-cloud-core grpcio google-cloud-monitoring datalab google-cloud-bigquery google-auth six requests protobuf\n",
        "!pip install --upgrade PyHamcrest google-api-core google-cloud-core grpcio datalab google-cloud-bigquery google-cloud-monitoring==0.31.1 google-auth==1.9 setuptools==41.0.0 six==1.13.0 requests==2.21.0 protobuf==3.8.0 tensorflow==2.1.0\n",
        "!pip install --upgrade matplotlib pandas h5py sklearn tqdm bleach pillow seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG2LKO5mJQvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import needed modules:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgaQLpyqJQvd",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac349da4-0241-44f4-81ff-20cf099e74a1"
      },
      "source": [
        "# import needed modules:\n",
        "\n",
        "# general python utilities\n",
        "import os\n",
        "import platform\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import functools\n",
        "import itertools as it\n",
        "import copy\n",
        "import warnings\n",
        "import pickle\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# recommended Python3 version >= 3.5\n",
        "print('Python version: {}'.format(platform.sys.version))\n",
        "\n",
        "# data-science & processing tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics\n",
        "import h5py\n",
        "\n",
        "# progress bar\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "# plotting utilities\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "#import tensorflow.keras as K\n",
        "\n",
        "# required TensorFlow version >= 2.0.0\n",
        "tf_version = tf.__version__\n",
        "print('TensorFlow version: {}'.format(tf_version))\n",
        "assert int(tf_version[0]) >= 2, \"Tensorflow version must be >= 2.0\"\n",
        "\n",
        "# seed random numbers for reproducibility\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "print('\\nImports Complete.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) \n",
            "[GCC 7.3.0]\n",
            "TensorFlow version: 2.1.0\n",
            "\n",
            "Imports Complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FifWz5azJQv2",
        "colab_type": "code",
        "colab": {},
        "outputId": "90e90750-9c82-4bfc-d5ef-cedad12b55e0"
      },
      "source": [
        "#import datasets, which already have been normalized, and processed. These are the images to analyze.\n",
        "#Each image is (224,224,3)\n",
        "normal = pickle.load(open(\"Data/normal.pkl\", \"rb\")) #Normal\n",
        "covid = pickle.load(open(\"Data/covid.pkl\", \"rb\")) #COVID\n",
        "tb = pickle.load(open(\"Data/tb.pkl\", \"rb\")) #TB\n",
        "bp = pickle.load(open(\"Data/bpneumonia.pkl\", \"rb\")) #Bacterial Pneumonia\n",
        "vp = pickle.load(open(\"Data/vpneumonia.pkl\", \"rb\")) #Bacterial Pneumonia\n",
        "print(len(normal))\n",
        "print(len(covid))\n",
        "print(len(tb))\n",
        "print(len(bp))\n",
        "print(len(vp))\n",
        "print(normal[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "485\n",
            "212\n",
            "394\n",
            "400\n",
            "400\n",
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS6_m6dBJQwJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "9fd100dd-3a0d-4f23-bf45-35acff0d0554"
      },
      "source": [
        "#Create train, validation, and testing datasets using SKLearn built in.\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Define Binary Data\n",
        "X = np.concatenate([normal,covid], axis = 0)\n",
        "Y = np.array([0]*len(normal) + [1]*len(covid)) #Let 0 be normal, COVID be 1.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
        "print(\"Binary-class Data:\")\n",
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "#Define Multi-class Data\n",
        "X_m = np.concatenate([normal,covid,tb,vp,bp], axis = 0)\n",
        "a = np.array([[1,0,0,0,0],]*len(normal))\n",
        "b = np.array([[0,1,0,0,0],]*len(covid))\n",
        "c = np.array([[0,0,1,0,0],]*len(tb))\n",
        "d = np.array([[0,0,0,1,0],]*len(vp))\n",
        "e = np.array([[0,0,0,0,1],]*len(bp))\n",
        "Y_m = np.concatenate((a,b,c,d,e),axis=0)\n",
        "\n",
        "X_mTrain, X_mTest, Y_mTrain, Y_mTest = train_test_split(X_m, Y_m, test_size=0.25, random_state=42)\n",
        "X_mTrain, X_mVal, Y_mTrain, Y_mVal = train_test_split(X_mTrain, Y_mTrain, test_size=0.25, random_state=42)\n",
        "print('Muli-class Data:')\n",
        "print(X_m.shape)\n",
        "print(X_mTrain.shape)\n",
        "print(X_mVal.shape)\n",
        "print(X_mTest.shape)\n",
        "print(Y_mTest.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary-class Data:\n",
            "(697, 224, 224, 3)\n",
            "(391, 224, 224, 3)\n",
            "(131, 224, 224, 3)\n",
            "(175, 224, 224, 3)\n",
            "Muli-class Data:\n",
            "(1891, 224, 224, 3)\n",
            "(1063, 224, 224, 3)\n",
            "(355, 224, 224, 3)\n",
            "(473, 224, 224, 3)\n",
            "(473, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74EABwULJQwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import vgg16, vgg19, resnet, resnet_v2, inception_v3, densenet\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_dOAJEdJQwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG16\n",
        "vgg16_base = vgg16.VGG16(weights = 'imagenet',\n",
        "                    include_top = False,\n",
        "                    input_shape = (224,224, 3))\n",
        "#VGG19\n",
        "vgg19_base = vgg19.VGG19(weights = 'imagenet',\n",
        "                    include_top = False,\n",
        "                    input_shape = (224,224, 3)) \n",
        "#ResNet 50 layers\n",
        "resnet50_base = resnet.ResNet50(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                               input_shape = (224,224,3))\n",
        "#ResNet 101 layers\n",
        "resnet101_base = resnet.ResNet101(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                               input_shape = (224,224,3))\n",
        "#ResNet 152 layers\n",
        "resnet152_base = resnet.ResNet152(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                               input_shape = (224,224,3))\n",
        "##ResNetV2 50 layers\n",
        "resnetV250_base = resnet_v2.ResNet50V2(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                              input_shape = (224,224,3))\n",
        "##ResNetV2 101 layers\n",
        "resnetV2101_base = resnet_v2.ResNet101V2(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                               input_shape = (224,224,3))\n",
        "##ResNetV2 152 layers\n",
        "resnetV2152_base = resnet_v2.ResNet152V2(weights='imagenet',\n",
        "                               include_top = False,\n",
        "                               input_shape = (224,224,3))\n",
        "\n",
        "##DenseNets with 121, 169, 201 layers\n",
        "densenet121 = tf.keras.applications.densenet.DenseNet121(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
        "densenet169 = tf.keras.applications.densenet.DenseNet169(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
        "densenet201 = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint #to save best model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GjorZ6zJQw3",
        "colab_type": "text"
      },
      "source": [
        "Suggestions about how to integrate different convolutional models for transfer learning were based on work done by Adrian Xu: https://towardsdatascience.com/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aazJmaa5JQw8",
        "colab_type": "text"
      },
      "source": [
        "#**Binary Classification Training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOFWbaRGJQxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG16/19\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [vgg19_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', #Use Binary CCE as loss.\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE), #use ADAM optimizer.\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_vgg16.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9oNjw9UJQxY",
        "colab_type": "code",
        "colab": {},
        "outputId": "0afddc11-9768-4666-b1ef-434019c20e0e"
      },
      "source": [
        "#ResNet 50\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.005\n",
        "\n",
        "bases = [resnet50_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(224, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_resnet50.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 68s 173ms/sample - loss: 7.4333 - acc: 0.6573 - val_loss: 0.6363 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 53s 134ms/sample - loss: 0.9786 - acc: 0.6624 - val_loss: 0.5892 - val_acc: 0.7328\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 53s 135ms/sample - loss: 0.7866 - acc: 0.6573 - val_loss: 0.6010 - val_acc: 0.7328\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 53s 134ms/sample - loss: 0.9645 - acc: 0.6471 - val_loss: 0.5999 - val_acc: 0.7328\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 52s 133ms/sample - loss: 0.7166 - acc: 0.6598 - val_loss: 0.5837 - val_acc: 0.7328\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 52s 133ms/sample - loss: 0.8963 - acc: 0.6419 - val_loss: 0.6019 - val_acc: 0.7328\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 53s 135ms/sample - loss: 2.2337 - acc: 0.6624 - val_loss: 0.8063 - val_acc: 0.7328\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 52s 133ms/sample - loss: 0.6175 - acc: 0.6624 - val_loss: 0.6994 - val_acc: 0.7328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9MPhQUoJQxv",
        "colab_type": "code",
        "colab": {},
        "outputId": "4ec2a893-00a6-4248-96f2-876e57058ad1"
      },
      "source": [
        "#ResNetV2 50\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV250_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(224, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_resnetV250.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 59s 152ms/sample - loss: 0.6600 - acc: 0.8824 - val_loss: 32.9589 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 46s 116ms/sample - loss: 0.2730 - acc: 0.9182 - val_loss: 1728.7814 - val_acc: 0.7328\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 45s 116ms/sample - loss: 0.1600 - acc: 0.9642 - val_loss: 758.2625 - val_acc: 0.7328\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 45s 116ms/sample - loss: 0.1093 - acc: 0.9668 - val_loss: 365.7360 - val_acc: 0.7328\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 0.0983 - acc: 0.9821 - val_loss: 197.6758 - val_acc: 0.7328\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 50s 128ms/sample - loss: 0.0843 - acc: 0.9668 - val_loss: 93.5975 - val_acc: 0.7481\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 50s 128ms/sample - loss: 0.0170 - acc: 0.9923 - val_loss: 56.2088 - val_acc: 0.7786\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 51s 131ms/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 5.6297 - val_acc: 0.8779\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 0.0407 - acc: 0.9949 - val_loss: 18.9221 - val_acc: 0.8168\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 44s 114ms/sample - loss: 0.3553 - acc: 0.9514 - val_loss: 42289.8450 - val_acc: 0.7328\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 1.3754 - acc: 0.8926 - val_loss: 8395954.0513 - val_acc: 0.7328\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 2.1701 - acc: 0.7494 - val_loss: 590598.6022 - val_acc: 0.7328\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 1.1150 - acc: 0.8312 - val_loss: 217645.8985 - val_acc: 0.3282\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 1.1175 - acc: 0.7775 - val_loss: 2289951.4048 - val_acc: 0.7252\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 45s 115ms/sample - loss: 1.2146 - acc: 0.6777 - val_loss: 2429272.0099 - val_acc: 0.6794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds-XvBYtJQyI",
        "colab_type": "code",
        "colab": {},
        "outputId": "8a1b6a10-e797-431a-e762-9265a280eaf5"
      },
      "source": [
        "#ResNetV2 101\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV2101_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_resnetV2101.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 102s 261ms/sample - loss: 1.5299 - acc: 0.8363 - val_loss: 77.5671 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 82s 210ms/sample - loss: 0.3296 - acc: 0.8977 - val_loss: 313.7915 - val_acc: 0.7328\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 82s 209ms/sample - loss: 0.1110 - acc: 0.9668 - val_loss: 296.1700 - val_acc: 0.7328\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 82s 211ms/sample - loss: 0.1935 - acc: 0.9616 - val_loss: 376.8039 - val_acc: 0.7328\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 90s 231ms/sample - loss: 0.0379 - acc: 0.9923 - val_loss: 44.9194 - val_acc: 0.8244\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 91s 232ms/sample - loss: 0.0341 - acc: 0.9821 - val_loss: 26.6185 - val_acc: 0.8550\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 89s 229ms/sample - loss: 0.0618 - acc: 0.9821 - val_loss: 3.3867 - val_acc: 0.9160\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 90s 229ms/sample - loss: 0.0061 - acc: 0.9974 - val_loss: 0.5141 - val_acc: 0.9771\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 82s 209ms/sample - loss: 0.0201 - acc: 0.9974 - val_loss: 6.4399 - val_acc: 0.8550\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 82s 210ms/sample - loss: 0.2585 - acc: 0.9437 - val_loss: 2.0398 - val_acc: 0.8397\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 83s 213ms/sample - loss: 0.4872 - acc: 0.9437 - val_loss: 3284.9876 - val_acc: 0.2290\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 86s 220ms/sample - loss: 0.6921 - acc: 0.8670 - val_loss: 29.2864 - val_acc: 0.5802\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 88s 225ms/sample - loss: 0.4111 - acc: 0.8056 - val_loss: 519.4924 - val_acc: 0.7328\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 86s 221ms/sample - loss: 0.3070 - acc: 0.8951 - val_loss: 3852121.3282 - val_acc: 0.7328\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 86s 220ms/sample - loss: 0.9214 - acc: 0.8082 - val_loss: 191681.2448 - val_acc: 0.7405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBnYSTQEJQyf",
        "colab_type": "code",
        "colab": {},
        "outputId": "3bd185af-0f4d-48d3-ab41-81a120f03463"
      },
      "source": [
        "#ResNetV2 152\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV2152_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(224, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_resnetV2152_extend.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 151s 387ms/sample - loss: 1.3997 - acc: 0.6496 - val_loss: 3996.2292 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 121s 310ms/sample - loss: 0.8400 - acc: 0.7059 - val_loss: 3.5440 - val_acc: 0.5115\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 133s 340ms/sample - loss: 0.4111 - acc: 0.8363 - val_loss: 313.1019 - val_acc: 0.7481\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 122s 311ms/sample - loss: 2.6930 - acc: 0.6394 - val_loss: 41719837.0687 - val_acc: 0.7328\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 121s 310ms/sample - loss: 3.4639 - acc: 0.6189 - val_loss: 1469.6208 - val_acc: 0.7328\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 122s 312ms/sample - loss: 1.0346 - acc: 0.6573 - val_loss: 63.1724 - val_acc: 0.7328\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 121s 310ms/sample - loss: 0.6860 - acc: 0.6496 - val_loss: 12.4409 - val_acc: 0.7328\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 122s 311ms/sample - loss: 0.6213 - acc: 0.6573 - val_loss: 12.1152 - val_acc: 0.6641\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 121s 309ms/sample - loss: 0.6155 - acc: 0.6675 - val_loss: 2.0144 - val_acc: 0.7099\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 122s 311ms/sample - loss: 0.6005 - acc: 0.6675 - val_loss: 0.6281 - val_acc: 0.7176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jNLU_CLA8N",
        "colab_type": "text"
      },
      "source": [
        "**Test DenseNet Versions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6gui90AJQyv",
        "colab_type": "code",
        "colab": {},
        "outputId": "727aa8e8-0819-4a30-ec8e-4f2137eaf8fc"
      },
      "source": [
        "#DenseNet\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet121]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_densenet121.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 95s 243ms/sample - loss: 2.4012 - acc: 0.8414 - val_loss: 52.5296 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 76s 195ms/sample - loss: 0.1907 - acc: 0.9412 - val_loss: 14.2003 - val_acc: 0.7328\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 80s 204ms/sample - loss: 0.0485 - acc: 0.9795 - val_loss: 1.1161 - val_acc: 0.7557\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 80s 205ms/sample - loss: 0.0155 - acc: 0.9923 - val_loss: 0.0557 - val_acc: 0.9771\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 80s 205ms/sample - loss: 0.0219 - acc: 0.9923 - val_loss: 0.0664 - val_acc: 0.9771\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 79s 201ms/sample - loss: 0.0098 - acc: 0.9949 - val_loss: 0.5559 - val_acc: 0.8015\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 79s 201ms/sample - loss: 0.0140 - acc: 0.9949 - val_loss: 0.2216 - val_acc: 0.9084\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 76s 195ms/sample - loss: 0.0052 - acc: 0.9974 - val_loss: 0.2428 - val_acc: 0.9160\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 80s 204ms/sample - loss: 0.0329 - acc: 0.9898 - val_loss: 0.2007 - val_acc: 0.9313\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 76s 194ms/sample - loss: 0.0177 - acc: 0.9923 - val_loss: 1.5504 - val_acc: 0.6031\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 77s 198ms/sample - loss: 0.0826 - acc: 0.9795 - val_loss: 3.1530 - val_acc: 0.3664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31y7LBJFJQy4",
        "colab_type": "code",
        "colab": {},
        "outputId": "9772caa5-c02a-4a2e-800b-539401212c3d"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet169]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_densenet169.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 391 samples, validate on 131 samples\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 112s 287ms/sample - loss: 3.9772 - acc: 0.7826 - val_loss: 22.2044 - val_acc: 0.7328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 83s 214ms/sample - loss: 0.3039 - acc: 0.9028 - val_loss: 31.5372 - val_acc: 0.7328\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 88s 224ms/sample - loss: 0.1157 - acc: 0.9616 - val_loss: 9.2682 - val_acc: 0.8397\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 83s 213ms/sample - loss: 0.1310 - acc: 0.9540 - val_loss: 17.0698 - val_acc: 0.7328\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 82s 210ms/sample - loss: 0.0413 - acc: 0.9872 - val_loss: 6.2696 - val_acc: 0.7634\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 83s 211ms/sample - loss: 0.0645 - acc: 0.9795 - val_loss: 3.0692 - val_acc: 0.7786\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 87s 222ms/sample - loss: 0.0236 - acc: 0.9898 - val_loss: 0.0575 - val_acc: 0.9695\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 82s 209ms/sample - loss: 0.0107 - acc: 0.9974 - val_loss: 0.8325 - val_acc: 0.7557\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 83s 212ms/sample - loss: 0.0117 - acc: 0.9974 - val_loss: 1.4968 - val_acc: 0.5420\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 83s 211ms/sample - loss: 0.0074 - acc: 0.9974 - val_loss: 2.0643 - val_acc: 0.4275\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 80s 205ms/sample - loss: 0.0047 - acc: 0.9974 - val_loss: 2.1587 - val_acc: 0.4351\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 81s 207ms/sample - loss: 0.0054 - acc: 0.9974 - val_loss: 2.8230 - val_acc: 0.3053\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 82s 211ms/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 4.1610 - val_acc: 0.2901\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 82s 209ms/sample - loss: 8.4850e-04 - acc: 1.0000 - val_loss: 4.3137 - val_acc: 0.3130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99314PfJQz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet201]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_densenet201.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_train,\n",
        "                       y = Y_train,\n",
        "                       validation_data = (X_val,Y_val),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,\n",
        "                      callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghaow7TFJQ0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load best models\n",
        "saved_model152 = tf.keras.models.load_model('best_models/best_resnetV2152.hdf5')\n",
        "saved_model101 = tf.keras.models.load_model(\"best_models/best_resnetV2101.hdf5\")\n",
        "saved_model50 = tf.keras.models.load_model(\"best_models/best_resnetV250.hdf5\")\n",
        "saved_model121=tf.keras.models.load_model('best_models/best_densenet121.hdf5')\n",
        "saved_model169=tf.keras.models.load_model('best_models/best_densenet169.hdf5')\n",
        "saved_model201=tf.keras.models.load_model('best_models/best_densenet201.hdf5')\n",
        "saved_model16=tf.keras.models.load_model('best_models/best_vgg16.hdf5')\n",
        "saved_model19=tf.keras.models.load_model('best_models/best_vgg19.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMHibXAnJQ0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions on Test set.\n",
        "y_pred_best50 = saved_model50.predict_classes(X_test)\n",
        "y_pred_best101 = saved_model101.predict_classes(X_test)\n",
        "y_pred_best152 = saved_model152.predict_classes(X_test)\n",
        "y_pred_best121 = saved_model121.predict_classes(X_test)\n",
        "y_pred_best169 = saved_model169.predict_classes(X_test)\n",
        "y_pred_best201 = saved_model201.predict_classes(X_test)\n",
        "y_pred_best16 = saved_model16.predict_classes(X_test)\n",
        "y_pred_best19 = saved_model19.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-nJJDjcJQ0e",
        "colab_type": "code",
        "colab": {},
        "outputId": "d979c5be-dd81-4c98-909d-86220ce237ac"
      },
      "source": [
        "#Get accuracy measurements using SKLearn.\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(Y_test, y_pred_best50.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best101.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best152.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best121.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best169.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best201.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best16.reshape(-1)))\n",
        "print(accuracy_score(Y_test, y_pred_best19.reshape(-1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9657142857142857\n",
            "0.9942857142857143\n",
            "0.96\n",
            "0.9657142857142857\n",
            "0.9657142857142857\n",
            "0.8857142857142857\n",
            "0.9485714285714286\n",
            "0.9314285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvlcJE7zLamM",
        "colab_type": "text"
      },
      "source": [
        "# **MULI-CLASS MODEL TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Z5ZQhXLW3B",
        "colab_type": "text"
      },
      "source": [
        "**VGG Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnMIa5t4JQ0t",
        "colab_type": "code",
        "colab": {},
        "outputId": "919aac65-e52c-4063-cbac-21a85e76f760"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [vgg16_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_vgg16.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 320s 301ms/sample - loss: 1.3122 - acc: 0.4214 - val_loss: 1.0477 - val_acc: 0.5014\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 317s 299ms/sample - loss: 0.9481 - acc: 0.5663 - val_loss: 0.9583 - val_acc: 0.6310\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 332s 313ms/sample - loss: 0.8875 - acc: 0.6011 - val_loss: 0.7916 - val_acc: 0.6479\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 337s 317ms/sample - loss: 0.7026 - acc: 0.6914 - val_loss: 0.8646 - val_acc: 0.6056\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 343s 323ms/sample - loss: 0.6397 - acc: 0.7187 - val_loss: 0.7083 - val_acc: 0.6930\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 332s 313ms/sample - loss: 0.5648 - acc: 0.7563 - val_loss: 1.0546 - val_acc: 0.5803\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 323s 304ms/sample - loss: 0.5231 - acc: 0.7836 - val_loss: 0.7581 - val_acc: 0.7070\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 316s 298ms/sample - loss: 0.4427 - acc: 0.8053 - val_loss: 0.8219 - val_acc: 0.6986\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 317s 298ms/sample - loss: 0.3716 - acc: 0.8495 - val_loss: 0.9555 - val_acc: 0.6592\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 317s 298ms/sample - loss: 0.3408 - acc: 0.8636 - val_loss: 0.7721 - val_acc: 0.6986\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 317s 298ms/sample - loss: 0.2783 - acc: 0.8796 - val_loss: 1.0849 - val_acc: 0.6986\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 317s 299ms/sample - loss: 0.2410 - acc: 0.9087 - val_loss: 1.1463 - val_acc: 0.6704\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 317s 299ms/sample - loss: 0.2545 - acc: 0.9059 - val_loss: 1.3177 - val_acc: 0.6394\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 316s 297ms/sample - loss: 0.2374 - acc: 0.9059 - val_loss: 1.2609 - val_acc: 0.6592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMr9CYe4JQ01",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7c094de-b44e-44ba-e618-201b4d371421"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [vgg19_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_vgg19.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 386s 363ms/sample - loss: 2.3200 - acc: 0.2295 - val_loss: 1.6493 - val_acc: 0.2169\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 1.6189 - acc: 0.2258 - val_loss: 1.5826 - val_acc: 0.2761\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 383s 360ms/sample - loss: 1.5937 - acc: 0.2399 - val_loss: 1.5815 - val_acc: 0.2085\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 398s 374ms/sample - loss: 1.5769 - acc: 0.2164 - val_loss: 1.5493 - val_acc: 0.2535\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 411s 387ms/sample - loss: 1.5012 - acc: 0.3302 - val_loss: 1.5907 - val_acc: 0.3014\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 414s 389ms/sample - loss: 1.6415 - acc: 0.2559 - val_loss: 1.5271 - val_acc: 0.2225\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 405s 381ms/sample - loss: 1.5453 - acc: 0.3029 - val_loss: 1.4651 - val_acc: 0.3577\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 1.3001 - acc: 0.4440 - val_loss: 1.1311 - val_acc: 0.4873\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 386s 363ms/sample - loss: 0.9958 - acc: 0.5597 - val_loss: 0.8900 - val_acc: 0.6000\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 1.1940 - acc: 0.4741 - val_loss: 1.0500 - val_acc: 0.5211\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 0.9648 - acc: 0.5635 - val_loss: 0.9132 - val_acc: 0.5521\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 0.8356 - acc: 0.6406 - val_loss: 0.8148 - val_acc: 0.6366\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 0.7826 - acc: 0.6425 - val_loss: 0.7355 - val_acc: 0.6817\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 0.6880 - acc: 0.6980 - val_loss: 0.7679 - val_acc: 0.6563\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 384s 362ms/sample - loss: 0.6228 - acc: 0.7215 - val_loss: 0.7379 - val_acc: 0.6732\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 0.6714 - acc: 0.6914 - val_loss: 0.7882 - val_acc: 0.6254\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 0.6174 - acc: 0.7215 - val_loss: 0.7747 - val_acc: 0.6620\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 401s 377ms/sample - loss: 0.6002 - acc: 0.7338 - val_loss: 0.7361 - val_acc: 0.6423\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 416s 391ms/sample - loss: 0.5436 - acc: 0.7582 - val_loss: 0.7585 - val_acc: 0.6873\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 411s 387ms/sample - loss: 0.5877 - acc: 0.7432 - val_loss: 0.7995 - val_acc: 0.6704\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 400s 376ms/sample - loss: 0.5397 - acc: 0.7582 - val_loss: 0.7444 - val_acc: 0.6789\n",
            "Epoch 22/30\n",
            "1063/1063 [==============================] - 389s 366ms/sample - loss: 0.5039 - acc: 0.7808 - val_loss: 0.8018 - val_acc: 0.6789\n",
            "Epoch 23/30\n",
            "1063/1063 [==============================] - 390s 367ms/sample - loss: 0.4415 - acc: 0.8071 - val_loss: 0.9407 - val_acc: 0.6901\n",
            "Epoch 24/30\n",
            "1063/1063 [==============================] - 390s 367ms/sample - loss: 0.4413 - acc: 0.8100 - val_loss: 0.7726 - val_acc: 0.6986\n",
            "Epoch 25/30\n",
            "1063/1063 [==============================] - 390s 367ms/sample - loss: 0.4603 - acc: 0.7959 - val_loss: 0.6797 - val_acc: 0.7155\n",
            "Epoch 26/30\n",
            "1063/1063 [==============================] - 386s 363ms/sample - loss: 0.4775 - acc: 0.7827 - val_loss: 0.8323 - val_acc: 0.6761\n",
            "Epoch 27/30\n",
            "1063/1063 [==============================] - 386s 363ms/sample - loss: 0.3483 - acc: 0.8542 - val_loss: 1.0014 - val_acc: 0.6676\n",
            "Epoch 28/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 0.3843 - acc: 0.8420 - val_loss: 0.8815 - val_acc: 0.6704\n",
            "Epoch 29/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 0.3371 - acc: 0.8664 - val_loss: 1.1867 - val_acc: 0.6817\n",
            "Epoch 30/30\n",
            "1063/1063 [==============================] - 387s 364ms/sample - loss: 0.3020 - acc: 0.8683 - val_loss: 0.8968 - val_acc: 0.6761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLPZomRLLpea",
        "colab_type": "text"
      },
      "source": [
        "**ResNet Models**  \n",
        "Based on testing on binary models, we skipped testing ResNetV1, because it underperformed compared to V2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhhXUU50JQ1C",
        "colab_type": "code",
        "colab": {},
        "outputId": "68af010e-23cd-41a5-a1c3-47ae2afbe88d"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV250_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_resnetV250.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 123s 116ms/sample - loss: 3.7814 - acc: 0.4252 - val_loss: 13.1750 - val_acc: 0.2986\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 120s 113ms/sample - loss: 0.7732 - acc: 0.6482 - val_loss: 4.4707 - val_acc: 0.4254\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 123s 116ms/sample - loss: 0.5001 - acc: 0.7789 - val_loss: 3.9459 - val_acc: 0.4535\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 130s 122ms/sample - loss: 0.2662 - acc: 0.8956 - val_loss: 3.4135 - val_acc: 0.5099\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 122s 115ms/sample - loss: 0.1079 - acc: 0.9661 - val_loss: 4.8626 - val_acc: 0.4648\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 128s 121ms/sample - loss: 0.0890 - acc: 0.9680 - val_loss: 4.7075 - val_acc: 0.5831\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 125s 117ms/sample - loss: 0.1568 - acc: 0.9426 - val_loss: 5.0605 - val_acc: 0.4338\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 128s 120ms/sample - loss: 0.2561 - acc: 0.9003 - val_loss: 4.7584 - val_acc: 0.4845\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 136s 128ms/sample - loss: 0.1541 - acc: 0.9407 - val_loss: 1.4925 - val_acc: 0.6648\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 126s 118ms/sample - loss: 0.0838 - acc: 0.9708 - val_loss: 2.2927 - val_acc: 0.5944\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 129s 121ms/sample - loss: 0.0683 - acc: 0.9727 - val_loss: 1.1583 - val_acc: 0.7352\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 124s 116ms/sample - loss: 0.0338 - acc: 0.9906 - val_loss: 1.2153 - val_acc: 0.7127\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 123s 115ms/sample - loss: 0.0239 - acc: 0.9953 - val_loss: 1.4402 - val_acc: 0.7324\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 124s 117ms/sample - loss: 0.0242 - acc: 0.9906 - val_loss: 1.6342 - val_acc: 0.7127\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 120s 113ms/sample - loss: 0.1017 - acc: 0.9737 - val_loss: 2.4888 - val_acc: 0.5324\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 116s 109ms/sample - loss: 0.1615 - acc: 0.9511 - val_loss: 1.5276 - val_acc: 0.5803\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 117s 110ms/sample - loss: 0.1249 - acc: 0.9501 - val_loss: 1.3090 - val_acc: 0.6479\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 116s 109ms/sample - loss: 0.0859 - acc: 0.9737 - val_loss: 1.6250 - val_acc: 0.6394\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 116s 109ms/sample - loss: 0.1041 - acc: 0.9633 - val_loss: 1.5553 - val_acc: 0.6225\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 116s 109ms/sample - loss: 0.0749 - acc: 0.9727 - val_loss: 1.2642 - val_acc: 0.6423\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 115s 108ms/sample - loss: 0.0378 - acc: 0.9887 - val_loss: 1.1424 - val_acc: 0.7070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il3OTbP4JQ1N",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf728b41-d79c-4dd3-a163-d89f721a6dd3"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV2101_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_resnetV2101.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 234s 221ms/sample - loss: 4.1757 - acc: 0.4130 - val_loss: 120.5962 - val_acc: 0.1746\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 219s 206ms/sample - loss: 0.9237 - acc: 0.6077 - val_loss: 36.5577 - val_acc: 0.2592\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.6827 - acc: 0.6858 - val_loss: 37.5808 - val_acc: 0.2113\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 219s 206ms/sample - loss: 0.5249 - acc: 0.7742 - val_loss: 19.3112 - val_acc: 0.2873\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 221s 208ms/sample - loss: 0.3226 - acc: 0.8711 - val_loss: 10.1444 - val_acc: 0.3324\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 218s 206ms/sample - loss: 0.1881 - acc: 0.9323 - val_loss: 9.8727 - val_acc: 0.3437\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 218s 205ms/sample - loss: 0.1451 - acc: 0.9454 - val_loss: 5.5322 - val_acc: 0.5042\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.2447 - acc: 0.9135 - val_loss: 8.5120 - val_acc: 0.3746\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 218s 205ms/sample - loss: 0.1718 - acc: 0.9398 - val_loss: 1.8253 - val_acc: 0.6451\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 217s 205ms/sample - loss: 0.1188 - acc: 0.9690 - val_loss: 2.0806 - val_acc: 0.6648\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 217s 204ms/sample - loss: 0.1735 - acc: 0.9398 - val_loss: 1.1739 - val_acc: 0.6845\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.1166 - acc: 0.9605 - val_loss: 1.6202 - val_acc: 0.6085\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 210s 197ms/sample - loss: 0.0308 - acc: 0.9897 - val_loss: 1.5325 - val_acc: 0.6592\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 211s 198ms/sample - loss: 0.0830 - acc: 0.9765 - val_loss: 1.5172 - val_acc: 0.5944\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 219s 206ms/sample - loss: 0.0741 - acc: 0.9784 - val_loss: 1.3044 - val_acc: 0.6394\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 224s 211ms/sample - loss: 0.0335 - acc: 0.9897 - val_loss: 1.1995 - val_acc: 0.6789\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 223s 210ms/sample - loss: 0.0181 - acc: 0.9944 - val_loss: 1.8812 - val_acc: 0.5887\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 240s 226ms/sample - loss: 0.0178 - acc: 0.9934 - val_loss: 1.6027 - val_acc: 0.7352\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 233s 219ms/sample - loss: 0.0087 - acc: 0.9981 - val_loss: 1.4260 - val_acc: 0.7296\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 224s 211ms/sample - loss: 0.0306 - acc: 0.9925 - val_loss: 1.5491 - val_acc: 0.6958\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 226s 212ms/sample - loss: 0.0251 - acc: 0.9897 - val_loss: 1.3062 - val_acc: 0.6845\n",
            "Epoch 22/30\n",
            "1063/1063 [==============================] - 217s 204ms/sample - loss: 0.0591 - acc: 0.9784 - val_loss: 2.0123 - val_acc: 0.5775\n",
            "Epoch 23/30\n",
            "1063/1063 [==============================] - 218s 205ms/sample - loss: 0.0660 - acc: 0.9765 - val_loss: 1.1659 - val_acc: 0.7549\n",
            "Epoch 24/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.0839 - acc: 0.9755 - val_loss: 1.3391 - val_acc: 0.7042\n",
            "Epoch 25/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.0491 - acc: 0.9774 - val_loss: 1.7945 - val_acc: 0.5718\n",
            "Epoch 26/30\n",
            "1063/1063 [==============================] - 214s 202ms/sample - loss: 0.0726 - acc: 0.9699 - val_loss: 2.3633 - val_acc: 0.5465\n",
            "Epoch 27/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.0438 - acc: 0.9840 - val_loss: 1.3817 - val_acc: 0.6761\n",
            "Epoch 28/30\n",
            "1063/1063 [==============================] - 211s 198ms/sample - loss: 0.0338 - acc: 0.9915 - val_loss: 1.0935 - val_acc: 0.6817\n",
            "Epoch 29/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.0174 - acc: 0.9972 - val_loss: 1.2506 - val_acc: 0.7014\n",
            "Epoch 30/30\n",
            "1063/1063 [==============================] - 209s 197ms/sample - loss: 0.0192 - acc: 0.9953 - val_loss: 1.8787 - val_acc: 0.6056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba4gZuIQJQ1X",
        "colab_type": "code",
        "colab": {},
        "outputId": "6a4c154b-565a-4fc1-c465-1cc45eac658b"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [resnetV2152_base]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_resnetV2152.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 338s 318ms/sample - loss: 3.2658 - acc: 0.4327 - val_loss: 7224.2168 - val_acc: 0.1859\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 304s 286ms/sample - loss: 0.8496 - acc: 0.6378 - val_loss: 1185.5992 - val_acc: 0.1859\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 316s 297ms/sample - loss: 0.5501 - acc: 0.7639 - val_loss: 48.8204 - val_acc: 0.2000\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 308s 290ms/sample - loss: 0.3956 - acc: 0.8410 - val_loss: 313.4380 - val_acc: 0.0901\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 322s 303ms/sample - loss: 0.1746 - acc: 0.9370 - val_loss: 7.3550 - val_acc: 0.3211\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 310s 292ms/sample - loss: 0.1614 - acc: 0.9492 - val_loss: 10.7557 - val_acc: 0.3014\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 341s 321ms/sample - loss: 0.1357 - acc: 0.9445 - val_loss: 11.0924 - val_acc: 0.4282\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 341s 320ms/sample - loss: 0.1709 - acc: 0.9511 - val_loss: 8.3701 - val_acc: 0.4451\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 384s 361ms/sample - loss: 0.2693 - acc: 0.9106 - val_loss: 3.1947 - val_acc: 0.4761\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 390s 366ms/sample - loss: 0.0719 - acc: 0.9784 - val_loss: 2.0026 - val_acc: 0.5690\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 380s 357ms/sample - loss: 0.0407 - acc: 0.9887 - val_loss: 1.7275 - val_acc: 0.6225\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 358s 337ms/sample - loss: 0.0862 - acc: 0.9765 - val_loss: 1.2360 - val_acc: 0.7352\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 348s 327ms/sample - loss: 0.0579 - acc: 0.9812 - val_loss: 1.7418 - val_acc: 0.6479\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 346s 325ms/sample - loss: 0.1268 - acc: 0.9539 - val_loss: 2.8795 - val_acc: 0.6592\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 317s 299ms/sample - loss: 0.1268 - acc: 0.9483 - val_loss: 2.2276 - val_acc: 0.6451\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 311s 293ms/sample - loss: 0.1106 - acc: 0.9643 - val_loss: 10.0196 - val_acc: 0.4592\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 312s 294ms/sample - loss: 0.0759 - acc: 0.9755 - val_loss: 2.5885 - val_acc: 0.6113\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 314s 295ms/sample - loss: 0.0724 - acc: 0.9718 - val_loss: 2.9825 - val_acc: 0.5408\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 315s 296ms/sample - loss: 0.0437 - acc: 0.9840 - val_loss: 5.6971 - val_acc: 0.4563\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 312s 293ms/sample - loss: 0.0444 - acc: 0.9878 - val_loss: 2.6347 - val_acc: 0.6789\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 313s 294ms/sample - loss: 0.0490 - acc: 0.9849 - val_loss: 2.3341 - val_acc: 0.6817\n",
            "Epoch 22/30\n",
            "1063/1063 [==============================] - 313s 294ms/sample - loss: 0.0657 - acc: 0.9774 - val_loss: 1.5304 - val_acc: 0.7324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtA8CHb5L9Pg",
        "colab_type": "text"
      },
      "source": [
        "**DenseNet Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWVX2HRbJQ1e",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a5909ca-5c74-400a-93d8-e397c123ae8f"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet121]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_densenet121.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 200s 188ms/sample - loss: 3.5263 - acc: 0.6858 - val_loss: 6.6722 - val_acc: 0.6338\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 171s 160ms/sample - loss: 1.2030 - acc: 0.7940 - val_loss: 7.8190 - val_acc: 0.5070\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 171s 161ms/sample - loss: 1.3551 - acc: 0.8034 - val_loss: 5.7126 - val_acc: 0.5380\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 172s 162ms/sample - loss: 0.5834 - acc: 0.8768 - val_loss: 5.9962 - val_acc: 0.6169\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 171s 161ms/sample - loss: 0.2065 - acc: 0.9389 - val_loss: 10.0463 - val_acc: 0.5521\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 175s 165ms/sample - loss: 0.2071 - acc: 0.9577 - val_loss: 4.1603 - val_acc: 0.6507\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 172s 161ms/sample - loss: 0.1482 - acc: 0.9624 - val_loss: 5.7691 - val_acc: 0.6366\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 176s 166ms/sample - loss: 0.2106 - acc: 0.9464 - val_loss: 2.5346 - val_acc: 0.6592\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 176s 166ms/sample - loss: 0.1970 - acc: 0.9501 - val_loss: 6.1227 - val_acc: 0.7042\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 173s 163ms/sample - loss: 0.1467 - acc: 0.9586 - val_loss: 3.2708 - val_acc: 0.6592\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 174s 164ms/sample - loss: 0.2310 - acc: 0.9520 - val_loss: 5.5678 - val_acc: 0.7352\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 173s 162ms/sample - loss: 0.0598 - acc: 0.9774 - val_loss: 5.6818 - val_acc: 0.6789\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 175s 164ms/sample - loss: 0.0339 - acc: 0.9887 - val_loss: 4.6508 - val_acc: 0.7099\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 172s 162ms/sample - loss: 0.0385 - acc: 0.9849 - val_loss: 3.9119 - val_acc: 0.6958\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 175s 165ms/sample - loss: 0.0287 - acc: 0.9906 - val_loss: 2.5103 - val_acc: 0.6761\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 171s 160ms/sample - loss: 0.0074 - acc: 0.9981 - val_loss: 2.5707 - val_acc: 0.7239\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 180s 169ms/sample - loss: 0.0044 - acc: 0.9991 - val_loss: 2.2823 - val_acc: 0.7183\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 179s 168ms/sample - loss: 5.8062e-04 - acc: 1.0000 - val_loss: 2.4827 - val_acc: 0.7239\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 182s 171ms/sample - loss: 0.0063 - acc: 0.9962 - val_loss: 2.2736 - val_acc: 0.7268\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 185s 174ms/sample - loss: 0.0033 - acc: 0.9981 - val_loss: 2.3667 - val_acc: 0.7296\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 186s 175ms/sample - loss: 0.0076 - acc: 0.9953 - val_loss: 2.9070 - val_acc: 0.7042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yKiaSY2JQ1n",
        "colab_type": "code",
        "colab": {},
        "outputId": "f82fccd2-baac-4437-e52b-a3d8fd2d353b"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet169]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_densenet169.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 252s 237ms/sample - loss: 8.0276 - acc: 0.3076 - val_loss: 2.6700 - val_acc: 0.3127\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 223s 210ms/sample - loss: 1.5155 - acc: 0.5550 - val_loss: 2.4263 - val_acc: 0.4000\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 213s 200ms/sample - loss: 0.9682 - acc: 0.6867 - val_loss: 4.3442 - val_acc: 0.2423\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 216s 203ms/sample - loss: 0.6502 - acc: 0.7667 - val_loss: 3.3862 - val_acc: 0.4592\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 207s 195ms/sample - loss: 0.5326 - acc: 0.7987 - val_loss: 3.6461 - val_acc: 0.3775\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 208s 196ms/sample - loss: 0.3595 - acc: 0.8664 - val_loss: 3.4419 - val_acc: 0.3606\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 208s 195ms/sample - loss: 0.2832 - acc: 0.9003 - val_loss: 2.5670 - val_acc: 0.4592\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 210s 197ms/sample - loss: 0.2456 - acc: 0.9247 - val_loss: 2.4116 - val_acc: 0.4732\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 210s 198ms/sample - loss: 0.1841 - acc: 0.9351 - val_loss: 1.7708 - val_acc: 0.5183\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 215s 202ms/sample - loss: 0.0621 - acc: 0.9765 - val_loss: 2.0259 - val_acc: 0.5662\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 209s 197ms/sample - loss: 0.0523 - acc: 0.9821 - val_loss: 1.8667 - val_acc: 0.5887\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 203s 191ms/sample - loss: 0.1331 - acc: 0.9539 - val_loss: 2.3257 - val_acc: 0.5296\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 205s 193ms/sample - loss: 0.0636 - acc: 0.9774 - val_loss: 2.9692 - val_acc: 0.4901\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 204s 192ms/sample - loss: 0.0340 - acc: 0.9868 - val_loss: 2.2327 - val_acc: 0.5521\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 201s 189ms/sample - loss: 0.0412 - acc: 0.9897 - val_loss: 2.9711 - val_acc: 0.4141\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 209s 196ms/sample - loss: 0.3160 - acc: 0.9304 - val_loss: 2.3710 - val_acc: 0.6056\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 203s 191ms/sample - loss: 0.0945 - acc: 0.9708 - val_loss: 2.3408 - val_acc: 0.5859\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 203s 191ms/sample - loss: 0.2466 - acc: 0.9116 - val_loss: 36.3483 - val_acc: 0.3775\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 205s 193ms/sample - loss: 0.1789 - acc: 0.9379 - val_loss: 7.3376 - val_acc: 0.5127\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 208s 196ms/sample - loss: 0.1065 - acc: 0.9595 - val_loss: 1.6980 - val_acc: 0.6338\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 205s 193ms/sample - loss: 0.0347 - acc: 0.9906 - val_loss: 2.4737 - val_acc: 0.5887\n",
            "Epoch 22/30\n",
            "1063/1063 [==============================] - 209s 196ms/sample - loss: 0.0173 - acc: 0.9962 - val_loss: 2.0697 - val_acc: 0.6056\n",
            "Epoch 23/30\n",
            "1063/1063 [==============================] - 215s 202ms/sample - loss: 0.0080 - acc: 0.9972 - val_loss: 2.3636 - val_acc: 0.5859\n",
            "Epoch 24/30\n",
            "1063/1063 [==============================] - 213s 201ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 2.3939 - val_acc: 0.5859\n",
            "Epoch 25/30\n",
            "1063/1063 [==============================] - 218s 205ms/sample - loss: 0.0061 - acc: 0.9972 - val_loss: 2.4125 - val_acc: 0.6169\n",
            "Epoch 26/30\n",
            "1063/1063 [==============================] - 224s 211ms/sample - loss: 0.0141 - acc: 0.9953 - val_loss: 2.5371 - val_acc: 0.5718\n",
            "Epoch 27/30\n",
            "1063/1063 [==============================] - 222s 209ms/sample - loss: 0.0208 - acc: 0.9934 - val_loss: 2.1355 - val_acc: 0.6169\n",
            "Epoch 28/30\n",
            "1063/1063 [==============================] - 220s 207ms/sample - loss: 0.0166 - acc: 0.9925 - val_loss: 1.7746 - val_acc: 0.7099\n",
            "Epoch 29/30\n",
            "1063/1063 [==============================] - 221s 208ms/sample - loss: 0.0108 - acc: 0.9991 - val_loss: 1.8629 - val_acc: 0.7014\n",
            "Epoch 30/30\n",
            "1063/1063 [==============================] - 215s 202ms/sample - loss: 0.0050 - acc: 0.9991 - val_loss: 1.5990 - val_acc: 0.7127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nveD1H3-JQ1w",
        "colab_type": "code",
        "colab": {},
        "outputId": "5b16b1f8-8e7b-4254-e0dc-f14e37670acf"
      },
      "source": [
        "BATCH_SIZE = 80\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE =0.0005\n",
        "\n",
        "bases = [densenet201]\n",
        "for base in bases:\n",
        "    base.training = False\n",
        "    model = models.Sequential()\n",
        "    model.add(base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation = \"relu\"))\n",
        "    model.add(layers.Dense(5, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "                  metrics= ['acc'])\n",
        "    earlyStopping = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=0, mode='max')\n",
        "    mcp_save = ModelCheckpoint(\"best_models/best_multi_densenet201.hdf5\", save_best_only=True, monitor='val_acc', mode = 'max')\n",
        "    result = model.fit(x = X_mTrain,\n",
        "                       y = Y_mTrain,\n",
        "                       validation_data = (X_mVal,Y_mVal),\n",
        "                       shuffle=True,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS,callbacks=[earlyStopping, mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1063 samples, validate on 355 samples\n",
            "Epoch 1/30\n",
            "1063/1063 [==============================] - 294s 277ms/sample - loss: 6.1193 - acc: 0.5146 - val_loss: 1247077.6197 - val_acc: 0.2986\n",
            "Epoch 2/30\n",
            "1063/1063 [==============================] - 257s 242ms/sample - loss: 1.8721 - acc: 0.6820 - val_loss: 30610.2322 - val_acc: 0.2225\n",
            "Epoch 3/30\n",
            "1063/1063 [==============================] - 269s 253ms/sample - loss: 0.8486 - acc: 0.7310 - val_loss: 70813.6311 - val_acc: 0.1972\n",
            "Epoch 4/30\n",
            "1063/1063 [==============================] - 267s 251ms/sample - loss: 0.5746 - acc: 0.7977 - val_loss: 19548.7437 - val_acc: 0.1972\n",
            "Epoch 5/30\n",
            "1063/1063 [==============================] - 283s 266ms/sample - loss: 0.4808 - acc: 0.7959 - val_loss: 3828.4940 - val_acc: 0.2789\n",
            "Epoch 6/30\n",
            "1063/1063 [==============================] - 296s 278ms/sample - loss: 0.3255 - acc: 0.8429 - val_loss: 1124.0873 - val_acc: 0.4423\n",
            "Epoch 7/30\n",
            "1063/1063 [==============================] - 295s 277ms/sample - loss: 0.2938 - acc: 0.8655 - val_loss: 326.6796 - val_acc: 0.5099\n",
            "Epoch 8/30\n",
            "1063/1063 [==============================] - 288s 271ms/sample - loss: 0.3511 - acc: 0.8476 - val_loss: 237.9796 - val_acc: 0.5296\n",
            "Epoch 9/30\n",
            "1063/1063 [==============================] - 289s 272ms/sample - loss: 0.2323 - acc: 0.8965 - val_loss: 80.3449 - val_acc: 0.5324\n",
            "Epoch 10/30\n",
            "1063/1063 [==============================] - 276s 260ms/sample - loss: 0.2062 - acc: 0.9276 - val_loss: 9.2373 - val_acc: 0.5775\n",
            "Epoch 11/30\n",
            "1063/1063 [==============================] - 267s 251ms/sample - loss: 0.3039 - acc: 0.8946 - val_loss: 2.8406 - val_acc: 0.5296\n",
            "Epoch 12/30\n",
            "1063/1063 [==============================] - 264s 249ms/sample - loss: 0.5001 - acc: 0.8429 - val_loss: 37.8321 - val_acc: 0.6056\n",
            "Epoch 13/30\n",
            "1063/1063 [==============================] - 260s 244ms/sample - loss: 0.4346 - acc: 0.8824 - val_loss: 34.0219 - val_acc: 0.6028\n",
            "Epoch 14/30\n",
            "1063/1063 [==============================] - 267s 251ms/sample - loss: 0.2785 - acc: 0.8946 - val_loss: 101.1145 - val_acc: 0.6761\n",
            "Epoch 15/30\n",
            "1063/1063 [==============================] - 259s 243ms/sample - loss: 0.2650 - acc: 0.9069 - val_loss: 35.7410 - val_acc: 0.6563\n",
            "Epoch 16/30\n",
            "1063/1063 [==============================] - 266s 250ms/sample - loss: 0.1649 - acc: 0.9304 - val_loss: 21.9586 - val_acc: 0.7070\n",
            "Epoch 17/30\n",
            "1063/1063 [==============================] - 263s 248ms/sample - loss: 0.0959 - acc: 0.9624 - val_loss: 12.9281 - val_acc: 0.7408\n",
            "Epoch 18/30\n",
            "1063/1063 [==============================] - 258s 242ms/sample - loss: 0.0510 - acc: 0.9774 - val_loss: 5.1622 - val_acc: 0.6479\n",
            "Epoch 19/30\n",
            "1063/1063 [==============================] - 259s 243ms/sample - loss: 0.0947 - acc: 0.9718 - val_loss: 2.9653 - val_acc: 0.6930\n",
            "Epoch 20/30\n",
            "1063/1063 [==============================] - 261s 246ms/sample - loss: 0.0807 - acc: 0.9802 - val_loss: 2.9030 - val_acc: 0.6817\n",
            "Epoch 21/30\n",
            "1063/1063 [==============================] - 266s 250ms/sample - loss: 0.0313 - acc: 0.9906 - val_loss: 1.5329 - val_acc: 0.7521\n",
            "Epoch 22/30\n",
            "1063/1063 [==============================] - 260s 245ms/sample - loss: 0.0168 - acc: 0.9944 - val_loss: 2.2024 - val_acc: 0.7493\n",
            "Epoch 23/30\n",
            "1063/1063 [==============================] - 267s 251ms/sample - loss: 0.0090 - acc: 0.9972 - val_loss: 1.8768 - val_acc: 0.7606\n",
            "Epoch 24/30\n",
            "1063/1063 [==============================] - 259s 244ms/sample - loss: 0.0071 - acc: 0.9972 - val_loss: 2.1427 - val_acc: 0.7155\n",
            "Epoch 25/30\n",
            "1063/1063 [==============================] - 269s 253ms/sample - loss: 0.0139 - acc: 0.9953 - val_loss: 1.7309 - val_acc: 0.7521\n",
            "Epoch 26/30\n",
            "1063/1063 [==============================] - 271s 255ms/sample - loss: 0.0374 - acc: 0.9887 - val_loss: 1.2450 - val_acc: 0.7549\n",
            "Epoch 27/30\n",
            " 160/1063 [===>..........................] - ETA: 3:36 - loss: 0.0990 - acc: 0.9688"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iro8EJ4JQ18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load saved multi-class labels\n",
        "saved_model152M = tf.keras.models.load_model('best_models/best_multi_resnetV2152.hdf5')\n",
        "saved_model101M = tf.keras.models.load_model(\"best_models/best_multi_resnetV2101.hdf5\")\n",
        "saved_model50M = tf.keras.models.load_model(\"best_models/best_multi_resnetV250.hdf5\")\n",
        "saved_model121M=tf.keras.models.load_model('best_models/best_multi_densenet121.hdf5')\n",
        "saved_model169M=tf.keras.models.load_model('best_models/best_multi_densenet169.hdf5')\n",
        "saved_model201M=tf.keras.models.load_model('best_models/best_multi_densenet201.hdf5')\n",
        "saved_model16M=tf.keras.models.load_model('best_models/best_multi_vgg16.hdf5')\n",
        "saved_model19M=tf.keras.models.load_model('best_models/best_multi_vgg19.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP2FNAVOJQ2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make test predictions\n",
        "y_pred_best50M = saved_model50M.predict_classes(X_mTest)\n",
        "y_pred_best101M = saved_model101M.predict_classes(X_mTest)\n",
        "y_pred_best152M = saved_model152M.predict_classes(X_mTest)\n",
        "y_pred_best121M = saved_model121M.predict_classes(X_mTest)\n",
        "y_pred_best169M = saved_model169M.predict_classes(X_mTest)\n",
        "y_pred_best201M = saved_model201M.predict_classes(X_mTest)\n",
        "y_pred_best16M = saved_model16M.predict_classes(X_mTest)\n",
        "y_pred_best19M = saved_model19M.predict_classes(X_mTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PXS2sR2JQ2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert one-hot encoding to class-encoding.\n",
        "Y_mTest=np.argmax(Y_mTest,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty7P4NOGJQ2V",
        "colab_type": "code",
        "colab": {},
        "outputId": "c00ffeca-aec6-4412-8873-5e70079ab464"
      },
      "source": [
        "#Get Recall and Precision scores.\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_mTest, y_pred_best121M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best169M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best201M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best50M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best101M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best152M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best16M.reshape(-1)))\n",
        "print(classification_report(Y_mTest, y_pred_best19M.reshape(-1)))\n",
        "#Get accuracy scores.\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(Y_mTest, y_pred_best121M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best169M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best201M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best50M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best101M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best152M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best16M.reshape(-1)))\n",
        "print(accuracy_score(Y_mTest, y_pred_best19M.reshape(-1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.78      0.56      0.65       124\n",
            "          1       0.71      0.87      0.78        53\n",
            "          2       0.66      0.70      0.68        98\n",
            "          3       0.59      0.70      0.64       101\n",
            "          4       0.64      0.62      0.63        97\n",
            "\n",
            "avg / total       0.68      0.67      0.66       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.71      0.81      0.75       124\n",
            "          1       0.93      0.77      0.85        53\n",
            "          2       0.73      0.74      0.74        98\n",
            "          3       0.64      0.64      0.64       101\n",
            "          4       0.66      0.59      0.62        97\n",
            "\n",
            "avg / total       0.71      0.71      0.71       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.72      0.77      0.74       124\n",
            "          1       0.86      0.70      0.77        53\n",
            "          2       0.69      0.71      0.70        98\n",
            "          3       0.72      0.50      0.59       101\n",
            "          4       0.60      0.76      0.67        97\n",
            "\n",
            "avg / total       0.70      0.69      0.69       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.69      0.91      0.79       124\n",
            "          1       0.98      0.87      0.92        53\n",
            "          2       0.93      0.53      0.68        98\n",
            "          3       0.61      0.78      0.68       101\n",
            "          4       0.71      0.57      0.63        97\n",
            "\n",
            "avg / total       0.76      0.73      0.73       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.77      0.85      0.81       124\n",
            "          1       0.59      0.96      0.73        53\n",
            "          2       0.94      0.49      0.64        98\n",
            "          3       0.74      0.55      0.63       101\n",
            "          4       0.64      0.79      0.71        97\n",
            "\n",
            "avg / total       0.75      0.71      0.71       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.77      0.84      0.80       124\n",
            "          1       0.88      0.96      0.92        53\n",
            "          2       0.84      0.72      0.78        98\n",
            "          3       0.68      0.81      0.74       101\n",
            "          4       0.78      0.60      0.68        97\n",
            "\n",
            "avg / total       0.78      0.77      0.77       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.70      0.67      0.68       124\n",
            "          1       0.65      0.83      0.73        53\n",
            "          2       0.76      0.76      0.76        98\n",
            "          3       0.67      0.69      0.68       101\n",
            "          4       0.67      0.59      0.63        97\n",
            "\n",
            "avg / total       0.69      0.69      0.69       473\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.69      0.76      0.72       124\n",
            "          1       0.81      0.83      0.82        53\n",
            "          2       0.79      0.66      0.72        98\n",
            "          3       0.70      0.63      0.67       101\n",
            "          4       0.66      0.74      0.70        97\n",
            "\n",
            "avg / total       0.72      0.72      0.72       473\n",
            "\n",
            "0.6659619450317125\n",
            "0.7103594080338267\n",
            "0.693446088794926\n",
            "0.7293868921775899\n",
            "0.7145877378435518\n",
            "0.773784355179704\n",
            "0.693446088794926\n",
            "0.7167019027484144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Fma19GJQ2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}